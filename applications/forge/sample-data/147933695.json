{"doi": null, "coreId": "147933695", "oai": "oai:infoscience.tind.io:115074", "magId": null, "identifiers": [], "title": "Joint Playback Delay and Buffer Optimization in Scalable Video Streaming", "authors": ["Wagner, Jean-Paul", "Frossard, Pascal"], "enrichments": {"references": [], "citationCount": null, "documentType": {"type": "unknown", "confidence": null}}, "contributors": [], "datePublished": "2007-12-20T15:21:10", "abstract": "This paper addresses the problem of the transmission of scalable video streams to a set of heterogeneous clients through a common bottleneck channel. The packet scheduling policy is typically crucial in such systems that target smooth media playback at all the receivers. In particular, the playback delays and the transmission strategy for the packets of the different layers have to be chosen carefully. When the same video is sent simultaneously to multiple clients that subscribe to different parts of the stream, the playback delay cannot be jointly minimized for all the clients. We therefore propose delay optimization strategies along with low complexity solutions for a fair distribution of the delay penalty among the different receivers. Once the delays are selected, we show that there exists a unique scheduling solution that minimizes the buffer occupancy at all the receivers. We derive an algorithm for computing the optimal sending trace, and we show that optimal scheduling has to respect the order of the packets in each media layer. Interestingly enough, solving both delay and buffer optimization problems sequentially leads to a jointly optimal solution when the channel is known. We finally propose a simple rate adaptation mechanism that copes with unexpected channel bandwidth variations by controlling the sending rate and dropping layers when the bandwidth becomes insufficient. Experimental results shows that it permits to reach close to optimal performances even if the channel knowledge is reduced. Rate adaptation provides an interesting alternative to conservative scheduling strategies, providing minor and controllable quality variations, but with a higher resulting average quality", "downloadUrl": "https://core.ac.uk/download/147933695.pdf", "fullTextIdentifier": "http://infoscience.epfl.ch/record/115074/files/CSVT_joint_delay_buffer_opt_TR.pdf", "pdfHashValue": "f732bc723d68d6a1557ab7b7fe79b926d595a735", "publisher": null, "journals": [], "language": null, "relations": [], "year": 2007, "topics": [], "subjects": ["Text"], "fullText": "SCHOOL OF ENGINEERING - STI\nSIGNAL PROCESSING INSTITUTE\nJean-Paul Wagner and Pascal Frossard\nCH-1015 LAUSANNE\nTelephone: +41 21 693 47 09\nTelefax: +41 21 693 7600\ne-mail: {jean-paul.wagner,pascal.frossard}@epfl.ch\n\u00c9COLE   POLYTECHNIQUE\r\nF\u00c9D\u00c9RALE DE LAUSANNE\nJOINT PLAYBACK DELAY AND BUFFER OPTIMIZATION IN\nSCALABLE VIDEO STREAMING.\nJean-Paul Wagner and Pascal Frossard\nEcole Polytechnique Fe\u00b4de\u00b4rale de Lausanne (EPFL)\nSignal Processing Institute Technical Report\nTR-ITS-2007.13\nDecember 20th, 2007\nPart of this work has been submitted to IEEE Transactions on Circuits and Systems for Video Technology.\nThis work has been partly supported by the Swiss National Science Foundation.\n2Joint Playback Delay and Buffer Optimization in Scalable\nVideo Streaming\nJean-Paul Wagner and Pascal Frossard\nEcole Polytechnique Fe\u00b4de\u00b4rale de Lausanne (EPFL)\nSignal Processing Institute - LTS4\nCH-1015 Lausanne\n{jean-paul.wagner, pascal.frossard}@epfl.ch\nAbstract\u2014This paper addresses the problem of the transmission of\nscalable video streams to a set of heterogeneous clients through a common\nbottleneck channel. The packet scheduling policy is typically crucial in\nsuch systems that target smooth media playback at all the receivers.\nIn particular, the playback delays and the transmission strategy for the\npackets of the different layers have to be chosen carefully. When the same\nvideo is sent simultaneously to multiple clients that subscribe to different\nparts of the stream, the playback delay cannot be jointly minimized for\nall the clients. We therefore propose delay optimization strategies along\nwith low complexity solutions for a fair distribution of the delay penalty\namong the different receivers. Once the delays are selected, we show\nthat there exists a unique scheduling solution that minimizes the buffer\noccupancy at all the receivers. We derive an algorithm for computing\nthe optimal sending trace, and we show that optimal scheduling has to\nrespect the order of the packets in each media layer. Interestingly enough,\nsolving both delay and buffer optimization problems sequentially leads to\na jointly optimal solution when the channel is known. We finally propose\na simple rate adaptation mechanism that copes with unexpected channel\nbandwidth variations by controlling the sending rate and dropping layers\nwhen the bandwidth becomes insufficient. Experimental results shows\nthat it permits to reach close to optimal performances even if the channel\nknowledge is reduced. Rate adaptation provides an interesting alternative\nto conservative scheduling strategies, providing minor and controllable\nquality variations, but with a higher resulting average quality.\nI. INTRODUCTION\nDue to the rapid evolutions in consumer electronics, the possibility\nto adapt to client preferences or to customize services becomes\npredominant in multimedia applications. We consider in this paper the\nproblem of the simultaneous delivery of a scalable media stream to\nheterogeneous clients that present different computing capabilities,\ndifferent access bandwidths, or different user requirements. Each\none of these clients selects to receive an appropriate subset of\nscalability layers, such that the received stream is decodable by the\nclient and satisfies its scalability needs. A typical example of such\na system is given in Figure 1, where a streaming server connects\nto heterogeneous clients directly or through a streaming proxy and\nbroadcasts a stored scalable media stream. Scalable video streaming\nsystems have generally to respect a bottleneck channel bandwidth,\nwhich prevents the immediate delivery of the media data to all\nthe clients. This limitation may be imposed by channel or disk\nbandwidth constraints, admission control or pre-determined traffic\nspecifications (e.g., TSPEC in the 802.1e wireless standard). Client\nbuffering capabilities may help to smooth the discrepancies between\nthe video source rate and the available bandwidth with a sustained\nquality, at the price however of an increased playback delay at\nthe client. It becomes therefore important to derive efficient packet\nscheduling strategies such that smooth playback can be ensured at\neach client and that the overall quality of service is maximized.\nThis work has been partly supported by the Swiss National Science\nFoundation.\nStreaming\nServer / Proxy\nStreaming\nServer\nIP Network\nHeterogeneous Clients\nFig. 1. Example of a scalable video streaming system.\nSeveral works have studied the problem of efficient packet schedul-\ning in different streaming scenarios. The problem of minimizing\nthe playback delay and buffering needs for a single receiver and\nnon-scalable streams under guaranteed rate constraints has been\npreviously addressed in [1]\u2013[3]. The problem has been nicely for-\nmalized in more general terms in [4] and [5]. In [6] the authors\ndiscuss optimal streaming of layered video under random bandwidth\nmodels, when the buffer is not constrained at the decoder. The error\nconcealment at the decoder is further considered in [7] where the\nscheduling decisions are based on a Markov Decision Process to\ncope with unpredictable bandwidth variations. The authors of [8]\naddress a similar scenario, where the number of layers that are\ntransmitted are computed from local decisions based on expected\nrun-time estimation. None of the above work however considers the\nproblem of multiple clients that participate together to the streaming\nsession.\nA scheduling algorithm that minimizes the buffer occupancy of a\nsingle client that receives a single stream has been proposed in [9].\nOur work extends this algorithm to provide jointly minimal buffer\noccupancy at heterogeneous clients that decode different subsets\nof the same layered stream. Optimal multiplexing for continuous\nmedia streaming is discussed in [10]. However the authors focus\non bandwidth efficiency and do not discuss the delay nor the buffer\noccupancy experienced by a client. Layered video streaming has been\nstudied in relation with multicast delivery schemes in [11], [12],\nwithout addressing the specific problem of heterogeneous receivers\nwith delay and buffer constraints. None of the cited papers addresses\nthe problem of multiplexing a layered video stream onto a broadcast\nchannel by targeting on one hand a set of minimal playback delays\nfor heterogeneous clients, and at the other hand the minimum buffer\noccupancy at each one of these clients.\nIn this paper, we propose to optimize the selection of the playback\ndelays for the different clients in order to have a fair distribution of the\ndelay penalty induced by the broadcast-like media transmission. We\n3show that the minimal playback delays cannot be jointly achieved\nfor all the clients, and we derive low cost optimization algorithms\nfor computing playback delay sets under different client prioritization\npolicies. Once the playback delays are given, we prove that minimum\nbuffer occupancy can be simultaneously attained for all the clients.\nThere is moreover a unique sending trace that attains the optimal\nsolution in this case, and we propose an algorithm that implements\nthe optimal transmission of the packets from the different layers.\nWhen both optimization problems are solved sequentially, the system\ncan design a mechanism that jointly optimizes delays and buffers.\nTo the best of our knowledge, this work is a first effort to address\nthe playback delay optimization problem, together with the buffer\nminimization problem for broadcast to heterogeneous clients. Finally,\nwe show how the optimal scheduling solution can be modified with a\nsimple adaptive rate control algorithm when the knowledge about the\nchannel bandwidth is limited. This solution provides an interesting\nalternative to conservative scheduling schemes in some practical\nscenarios with unpredictable bandwidth, while it offers an improved\naverage quality but minor and controllable quality variations.\nThe paper is organized as follows: we provide an overview of the\nsystem under consideration and discuss media scheduling properties\nin Section II. We present the delay optimization solutions in Section\nIII, and we analyze the buffer minimization problem in Section IV.\nSection V introduces an adaptive rate control algorithm to cope with\nunexpected bandwidth variations and discusses its performance in\npractical scenarios.\nII. SCALABLE VIDEO BROADCAST\nA. System Overview\nScheduler\nMedia ...\nChannel \n2\n1\n( )\n1 1( )\n1\n( )\n...\nStreaming\nserver\n Network\nReceiver\npopulation\n...\n\u03bb \u03bb \u03bb\n\u03bb \u03bb \u03bb\nnetwork feedbacks\nl l\nFig. 2. Formal view of the system.\nWe present an overview of the system under consideration in this\npaper. A formal representation of the system is given in Figure 2.\nA streaming server sends a scalable media stream to a population of\nreceivers through a bottleneck channel. This bottleneck represents\nfor example a shared channel or network segment with limited\nbandwidth, or the disk bandwidth limitations in a video-on-demand\nserver. The bottleneck channel is given by its bitrate c(t), which\nindicates how many bits the channel is able to transmit at any time\nt, and possibly by a maximum network latency \u2206.\nGenerally, the server\u2019s knowledge about the channel availability\nis extracted from client or network feedback. In this paper we will\nassume perfect channel knowledge at the server, which leads to an\nupper bound on achievable performance for any predictive scheme,\nwhere the server estimates the available channel. In particular, this\nassumption is verified for constant bit rate channels or when the\nbandwidth is controlled by deterministic guarantees (e.g., TSPEC in\nthe recent 802.11e wireless protocol). In the rest of this paper, the\nchannel rate c(t) is the rate available for the broadcast application,\nand we do not limit the study to any particular congestion control or\nrate allocation strategy.\nThe scalable video stream is built on several hierarchical layers.\nEach of the L layers is completely determined by its source or playout\ntrace \u03bbl(t), 1 \u2264 l \u2264 L, which indicates the size of the layer l at time\nt. When a hierarchy exists between video layers, the decoding of\nlayer l is made contingent on the correct decoding of all inferior\nlayers, from 1 up to l \u2212 1. Batches of clients simultaneously access\nthe same video sequence, possibly with different scalability levels.\nThe receivers are grouped together into L sets, based on the number\nof video layers or the resolution that they have requested. We denote\nas Rl, (1 \u2264 l \u2264 L) the set of clients that receive all layers up to the\nlth layer.\nAfter the first bit is sent by the server, each receiver in Rl buffers\nthe video data for a playback delay Dl. The video bits are stored in\nthe receiving buffer, whose content at any time is further denoted as\nBl(t). After the initial playback delay, the receiver decodes and plays\ncontinuously a video whose resolution corresponds to the series of\nadditive layers it has requested. The playback delay can be different\nfor each group of receivers Rl. However, the set of playback delays\nD = {Dl}Ll=1 should be chosen such that non-disruptive playback\nof the sequence can be achieved for any set of receivers Rl, i.e.,\nsuch that no buffer underflow occurs at any receiver 1. At the same\ntime, the choice of the playback delay impacts the quality-of-service\nperceived by the end-user. It therefore requires an efficient packet\nscheduling strategy in order to reach a proper trade-off between user\nexperience and resilience to underflows and bandwidth limitations.\nBefore addressing the problems of playback delay selection, we\ndescribe below the problem of packet scheduling in media streaming\napplications that generally impose strict timing constraints.\nB. Media Scheduling Formalism\nWe now describe in more details the packet scheduling characteris-\ntics in media streaming applications. When the channel is constrained,\nthe streaming server has generally to implement effective scheduling\nalgorithms, in order to ensure timely delivery of media packets and to\navoid buffer underflow at receivers. The packet transmission strategy\nis chosen in order to meet criteria such as desired distortion or\ndelay [13], [14], or maximum utilization of the available channel\nbitrate. The packet scheduler outputs a stream with a sending rate\nx(t) \u2264 c(t),\u2200t that indicates the number of bits fed into the channel\nat any time instant t.\nWe denote the cumulative source, sending and channel rate func-\ntions with capital letters (S,X,C), where a cumulative rate function\nis defined as the total number of bits that have been counted since\ntime t = 0. For example, C(t) =\nR t\n0\nc(u)du is the number of bits\nthe channel can transmit up to time t. Note that the cumulative rate\nfunctions are all wide-sense increasing in t. We further define sD(t)\nas the number of bits consumed by the decoder that starts playing\nvideo after a playback delay D. It is written as:\nsD(t) =\n\uf6be\n0 , 0 \u2264 t < D\ns(t\u2212D) , t \u2265 D\nSD(t) = S(t\u2212D) is the corresponding cumulative function.\nThe scheduler has to ensure that the client does not experience any\nbuffer starvation, when the video decoding starts after a playback de-\nlay that has been selected a priori. Figure 3 illustrates the importance\nof the playback delay for smooth video decoding in a scenario with\n1In the remaining of the paper, we use Rl to design a set of receivers\nthat subscribe to the resolution level l or one of the receivers in this set,\ninterchangeably.\n4t\nbit\nt\nbit\nFig. 3. Left: Playback delay and buffer underflow prevention. Right:\nSchedulable play-out trace and a corresponding sending rate trace.\na single client. If the client starts playback at the reception of the\nfirst bit, a buffer underflow occurs at time tc. Starting playback at\nthe client after D time units makes sure that the buffer underflow\ndoes not occur. We say that a source trace s(t) is schedulable over\na channel with available bandwidth c(t), with a playback delay D,\nif the following schedulability condition holds for all t:\nSD(t) \u2264 C(t\u2212\u2206) (1)\nIf the condition (1) is met, this implies that the server can find a\nscheduling solution or equivalently a sending trace x(t) such that\neach of the following necessary conditions are satisfied for all t:\nSD(t) \u2264 X(t\u2212\u2206) (2)\nx(t) \u2264 c(t). (3)\nThe first inequality makes sure that the server transmits a number\nof bits that is sufficient for decoding the video stream at all time\ninstants t, with a playback delay D and a maximum network latency\n\u2206. As a constant value of \u2206 implies a simple time shift in each\nof the above inequalities, we will consider that \u2206 = 0 for the sake\nof clarity and without loss of generality in the remainder of this\npaper. The second condition simply imposes that the number of bits\ntransmitted by the server at any time instant is not larger than the\nchannel rate. Note that the latter condition implies X(t) \u2264 C(t),\u2200t,\nbut that the reverse is not true. If the playback delay D is chosen\nsuch that the above conditions hold, a scheduling solution can be\nfound. Each valid scheduling strategy generates a sending rate x(t)\nthat satisfies Eqs. (2) and (3) for all t. Finally, the buffer occupancy of\na media client that receives a data rate X(t) and plays out a sending\ntrace SD(t) is given by:\nB(t) = X(t)\u2212 SD(t),\u2200t. (4)\nThe above equation shows that the buffer occupancy is dependent\non the choice of the playback delay, so that the joint minimization\nof both components becomes non-trivial. We first present a method\nto optimize the choice of the playback delays in scalable streaming\nsystems. Then we show how to define a scheduling strategy that\nminimizes also the buffer occupancy.\nIII. PLAYBACK DELAY OPTIMIZATION\nA. Preliminaries\nIn this section, we discuss the choice of the playback delays for the\ndifferent sets of clients Rl that simultaneously receive the scalable\nstream. Small playback delays usually lead to a better quality of\nservice, and we will present algorithms for optimizing the choice of\nplayback delays, under different metrics. We first give a preliminary\nanalysis of the playback delay, and define the minimal playback delay\nfor a client Rl that decodes l layers of the scalable video stream.\nWe introduce here some general results inspired from [15]. Sup-\npose that we have two increasing non-zero functions F (t) and G(t)\nsuch that limt\u2192\u221e F (t) \u2265 limt\u2192\u221eG(t). We define the (maximum)\nhorizontal distance between F (t) and G(t) as follows:\nh(G,F ) = sup\nt\n`\nF\u22121 (G(t))\u2212 t\n\u00b4\n, (5)\nwhere F\u22121(t) = min {t : F (t) \u2265 x} is a pseudo-inverse of F (t).\nThe following relations hold:\nh(G,F ) = 0 \u21d4 F (t) \u2265 G(t),\u2200t and (6)\n\u2203\u03c4 s.t. F (\u03c4 ) = G(\u03c4 ) (7)\nh(G,F ) < 0 \u21d4 F (t) > G(t),\u2200t (8)\nh(G,F ) > 0 \u21d4 \u2203\u03c4 s.t. F (\u03c4 ) < G(\u03c4 ). (9)\nWhen F (t) and G(t) respectively represent the cumulative channel\nand source traces, the horizontal distance between F and G represents\nthe minimal playback delay that is necessary for a smooth decoding\nof the source stream. In other words, it represents the minimal shift\nthat as to be applied on G, such that the schedulability condition is\nverified. Formally, we have the following property.\nProperty 1: If h(G, F ) > 0 and G\u2032(t) = G(t \u2212 h(G,F )), then\nh(G\u2032, F ) = 0. In other words, h(G,F ) is the minimum shift we\nneed to apply on G(t), so that F (t) \u2265 G\u2032(t), \u2200t.\nWith multiple traces, we have also:\nProperty 2: Let F (t), G(t) and G\u2032(t) be non-decreasing func-\ntions such that G\u2032(t) > G(t), \u2200t. Then: h(G\u2032, F ) > h(G, F ).\nIndeed by the definition of h(\u00b7) and F\u22121(\u00b7), and because F (t) is\nnon-decreasing, the result follows immediately, as F\u22121 (G\u2032(t)) >\nF\u22121 (G(t)), \u2200t. Similarly, if G\u2032(t) < G(t), \u2200t then h(G\u2032, F ) <\nh(G,F ).\nWe can therefore define the minimal playback delay Dlmin for\nsmooth playback at the receiver Rl. It is given by\nDlmin = h\n\u201c\nSl(t), C(t)\n\u201d\n, (10)\nwhere Sl(t) =\nPl\nk=1 \u039b\nk(t) is the cumulative rate of the stream\nat resolution l. From Property 2, we know that Dlmin \u2264 Dl+1min,\n\u22001 \u2264 l \u2264 L \u2212 1, since the rate traces are positive valued\nfunctions, and Sl+1(t) \u2265 Sl(t),\u2200t. If the layer l is decoded after\na minimal playback delay Dlmin, the only valid scheduling solutions\nare strategies where the playback delay for layers k < l is not any\nlarger than Dlmin . It is actually not possible to reduce the minimal\nplayback delay for the client Rl, even by changing the scheduling of\nthe lower layer streams.\nLet us define ~\u03b4 = [\u03b41, .., \u03b4l], with \u03b41 \u2265 \u03b42 \u2265 . . . \u2265 \u03b4l \u2265 0. We\nhave the following Lemma, which shows that the minimal playback\ndelay required for a smooth decoding of the resolution level l cannot\nbe smaller than Dlmin, even if the lower layers are decoded with a\nsmaller delay.\nLemma 1: Consider a set of L non-decreasing functions\n{H l(t)}Ll=1 and a non-decreasing function F (t), defined \u2200t. We have,\n\u2200l, 1 \u2265 l \u2265 L:\nh\n\u201c\nGl, F\n\u201d\n\u2264 h\n\u201c\nGl~\u03b4, F\n\u201d\n,\nwhere Gl(t) =\nPl\nk=1H\nk(t) and Gl~\u03b4(t) =\nPl\nk=1H\nk(t+ \u03b4k).\nProof: As the functions {Gl(t)}Ll=1 are non-decreasing, we have,\n\u2200l, 1 \u2265 l \u2265 L and \u2200\u03b4l \u2265 0: H l(t) \u2264 H l (t+ \u03b4l). Thus, \u2200l, 1 \u2265 l \u2265\nL,\nGl(t) \u2264 Gl~\u03b4(t) ,\u2200t.\nFrom Property 2, it follows that h\n`\nGl, F\n\u00b4\n\u2264 h\n`\nGl~\u03b4, F\n\u00b4\n.\nFrom the above results we conclude that any playback delay\nsmaller than Dlmin results in a buffer underflow at the receiver\nRl, while any larger playback delay allows for decoding without\nexperiencing a buffer underflow. This permits to derive a simple\n5bisection search algorithm for computing the minimal delay Dlmin,\nsimilar to Algorithm 1.\nAlgorithm 1 Dmin = getDmin (C(t), S(t))\n1: Dlow \u21d0 0\n2: Dhigh \u21d0some large value\n3: while (Dhigh \u2212Dlow) > 1 do\n4: Dtest \u21d0\nj\nDlow+Dhigh\n2\nk\n5: if S (t\u2212Dtest) \u2264 C(t), \u2200t then\n6: Dhigh \u21d0 Dtest\n7: else\n8: Dlow \u21d0 Dtest\n9: end if\n10: end while\n11: Dmin = Dtest\nIt is important to note here that achieving the minimum playback\ndelay for a given layer l does not necessarily guarantee that a\nminimum playback delay is also achieved for any other layer. In\ngeneral, if the transmission strategy is chosen in order to minimize\nthe delay at layer l, without considering any other layer k, with k < l,\nthe clients that only subscribe to the lower layers are penalized by a\nplayback delay that might be larger than necessary. If, in the contrary,\nthe scheduler decides to minimize the playback delay for layer k, it\ngenerally increases the playback delay any other layer l, with l > k.\nThe choice of playback delay therefore results from a typical trade-\noff between the delays imposed to the different layers, since the\ndelays cannot be minimized simultaneously for all the layers. When\nthe playback penalty is increased for the lower layers, it typically\nsaves channel bits that can be used for decreasing the playback\ndelay penalty for higher layers. In the next section, we formulate\nan optimization problem for the choice of the playback delays for\ndifferent policies.\nB. Problem Formulation\nConsider a channel given by its cumulative rate trace C(t), and a\nset of L hierarchically coded layers given by their cumulative source\nrate traces {Sl}Ll=1. The channel connects a streaming server to L\nsets of receivers {Rl}Ll=1, that simultaneously subscribe to layers up\nto l. Let D = {Dl}Ll=1, with D1 \u2264 D2 \u2264 . . . \u2264 DL \u2264 Dmax denote\nthe set of playback delays imposed to the different sets of clients.\nThe joint minimization of the playback delays for all heterogeneous\nreceivers is generally not achievable in broadcast-like scenarios, as\ndiscussed above. We therefore formulate the following optimization\nproblem, which targets a fair selection of the playback delays. Let\nDlmin represents the minimal playback delay that can be offered to\nthe client Rl, when other clients are not considered. A fair distribution\nof the playback delay among the different clients can be achieved by\ncontrolling the penalties \u2206 = [\u22061, ..\u2206L], with \u2206l = Dl \u2212 Dlmin,\n1 \u2264 l \u2264 L, in addition to minimizing the playback delays. The\nplayback delays can therefore by chosen as\nDopt = argmin\nD\n\u03d5\n\u201c\n{Dl}, {\u2206l}\n\u201d\n(11)\nunder the condition that SlD(t) \u2264 C(t) \u2200l, 1 \u2264 l \u2264 L, where\nSlD(t) =\nPl\ni=1 \u039b\ni\nDi(t), i.e., all the traces are schedulable from Eq.\n(1). The function \u03d5 is a generic cost function that combines the\naverage playback delay and the delay penalty imposed to each layer\ndue to the broadcast-like distribution. Finding the best set of playback\ndelays Dopt is actually a combinatorial optimization problem, and its\nsolution generally implies a full search algorithm. We show in the\nnext sections how the search space can be reduced for solving the\ngeneric optimization problem of Eq. (11). We also present efficient\nsolutions to the problems of fair or weighted distribution of the delay\npenalty \u2206l between the different layers.\nC. Reduced search space\nIn order to solve the joint delay optimization problem, we propose\nto limit the search space of possible delay values. We know already\nfrom the above discussion that the minimal playback delay for clients\nthat decode the stream up to layer l, is Dlmin. It corresponds to\nthe lowest achievable delay, when clients Rk with k 6= l are not\nconsidered in the delay computation. Generally, the playback delay\nfor layer l is larger than Dlmin when the scheduler also tries to reduce\nthe delay for the lower layers 1 \u2264 k \u2264 l. In order to reduce the\nsearch space, we are looking for a reasonable upper-limit on the\nsearch interval. From Lemma 1, the worse case policy for clients\nRl consists in minimizing iteratively the delays for all the clients\nRk with 1 \u2264 k \u2264 l. We describe below the greedy delay allocation\npolicy, and we denote the resulting delay Dlgreedy .\nThe greedy delay allocation first minimizes the playback delay of\nthe first layer, which is thus decoded after D1greedy = D1min . It then\niteratively allocates the smallest possible delay to the different layers,\ngiven the greedy delay allocation for the lower layers. Formally, we\ndenote the available channel bandwidth for transmitting the layer l\nas Cl(t) = C(t)\u2212\nPl\u22121\nk=1 \u039b\nk(t\u2212Dkgreedy). Therefore, the minimal\nplayback delay for layer l becomes h(Cl,\u039bl) under the greedy\nallocation policy. This scenario results in an upper bound DLgreedy\non the playback delay for the highest layer L, when all playback\ndelays are chosen in a greedy manner. In particular, delays that are\nlarger than DLgreedy also provide valid scheduling solutions. However,\nincreasing the playback delay DL does not reduce the playback delay\nof the lower layers, and rather contribute to increasing the standard\ndeviation of the penalties given in Eq. (11). The delays obtained by\nthe greedy allocation can therefore be safely considered as the upper-\nlimits of the search intervals. The greedy layered scheduling strategy\nis shown in Algorithm 2.\nAlgorithm 2\n`\u02d8\nDlgreedy\n\u00af\u00b4\n= GreedyD\n`\nC(t), {\u039bl(t)}\n\u00b4\n1: C1(t)\u21d0 C(t)\n2: for l = 1 to L do\n3: Dlgreedy \u21d0 getDmin\n`\nCl(t),\u039bl(t)\n\u00b4\n4: Cl+1(t)\u21d0 Cl(t)\u2212 \u039bl(t\u2212Dlgreedy)\n5: end for\nAs the greedy delay allocation provides the worst case solution for\nminimizing the delay for all the receivers, we can limit the search\ndomain for computing the best set of playback delays to the interval\n[Dlmin,D\nl\ngreedy ], \u2200l. In addition, due to the hierarchical nature of\nthe scalable video stream, we know the delay can only take non-\ndecreasing values when the number of layers increases (i.e., Dk \u2264 Dl\nwhen k \u2264 l). We can therefore limit the number of potential\nsolutions that need to be tested for optimality by the search algorithm,\nby setting the condition that DL \u2208 [DLmin,DLgreedy ]. Then, for\neach possible value of DL, we constrain the search algorithm to\ntest values of DL\u22121 such that DL\u22121 \u2208 [DL\u22121min ,D\nL]. The search\nproceeds iteratively and only test values of delay Dl, such that\nDl \u2208 [Dlmin,D\nl+1], for l = L..1. Using this simple method, the\nset of playback delays that minimizes Eq. (11) can be identified with\nhigh probability for most cost functions \u03d5 that tends to minimize\nthe average playback delay. The search space of feasible solutions is\nhowever drastically reduced compared to a full search algorithm.\n6D. Fair penalty distribution\nIn order to have a fair policy among the different clients Rl, we\ncan distribute the playback delays such that the standard deviation of\nthe penalties \u2206 = [\u22061, . . . ,\u2206L] is minimized. If the average penalty\nis given by \u00b5 = E[\u2206l], the playback delays can thus be chosen such\nthat\nDopt = argmin\nD\nE\n\u02c6\n(\u2206\u2212 \u00b5)2\n\u02dc (12)\nunder the condition that SlD(t) \u2264 C(t) \u2200l, 1 \u2264 l \u2264 L, i.e., all the\ntraces are schedulable from Eq. (1).\nWe propose a low complexity algorithm for computing the optimal\nplayback delay set Dopt in the sense of Eq. (12). We can observe\nthat the minimal value of the cost function is reached when all the\npenalties are equivalent, i.e., \u2206k = \u2206l, \u2200k, l. Any set of delays\nD =\n\u02d8\nDl|Dl = Dlmin +\u2206l\n\u00afL\nl=1\n, where \u2206l = K, \u2200l minimizes the\ncost of Eq. (11). In other words the source traces of all layers need to\nbe delayed by K units relative to their respective minimal playback\ndelay Dlmin. Given the set of minimum playback delays Dmin , we\ncan construct an aggregate source rate trace SLDmin(t), defined as:\nSLDmin(t) =\nLX\nl=1\n\u039bl\n\u201c\nt\u2212Dlmin\n\u201d\n. (13)\nIf the trace SLDmin(t) is schedulable, it represents an ideal solution\nwhere all layers can be decoded jointly with minimal delay. If it is\nnot the case, the playback delay can be increased in the same manner\nfor all layers, such the trace becomes schedulable. It corresponds to\nshifting the aggregate source trace by the smallest delay K, such that\nSLDmin(t\u2212K) \u2264 C(t),\u2200t. In other words, we can compute K as\nK = h\n\u201c\nSLDmin , C\n\u201d\n, (14)\nand that can be achieved by running the Algorithm 1. Hence the\ncomplexity involved in finding the solution is that of the bisection\nsearch algorithm used in Algorithm 1, i.e., O(log(trace length)).\nThe solution is obviously equivalent to the optimal solution of the\nalgorithm in the previous section, when it lies in the reduced search\nspace.\n0 200 400 600 800 1000 1200 1400 1600\n0\n2\n4\n6\n8\n10\n12\ntime in frames (30 fps)\n[M\nbi\nt]\nPlayout of     \nLayer 1 starts \nPlayout of     \nLayer 2 starts Playout of     Layer 3 starts \nC(t)\n\u039b1(t\u2212D1f ) + \u039b\n2(t\u2212D2f ) + \u039b\n3(t\u2212D3f )\n\u039b1(t\u2212D3\nmin) + \u039b\n2(t\u2212D3min) + \u039b3(t\u2212D3min)\nFig. 4. The channel can support 3 layers of the encoded stream. The dashed\ncurve shows the aggregate playout curve of the 3 layers with fair values of\nthe playback delays Df . The aggregate playout curve of the 3 layers using\nplayback delay D3min is shown for reference (dotted line).\nWe illustrate the solution with fair distribution of the delay penal-\nties in Figure 4. We have encoded a composite video sequences in\nQCIF format at 30 frame per second, using the MoMuSys MPEG-4\nFGS [16] reference codec. The channel is a piecewise CBR channel\nthat provides a mean rate of 128kbps at the beginning, then improves\nto 256kbps and finally to 384kbps. Using the fair playback delay\ndistribution proposed above, the playout can begin after a playback\ndelay equivalent to 137 frames at receivers of set R1. The playback\ndelays for layer 2 and 3 are of 199 and 730 frames respectively.\nThe relative playback delay penalty per client set, compared to\ntheir respective Dlmin value, is equivalent to 135 frames for all\nclients. Note that the gain in delay for clients in sets R1 and R2\nis enormous when compared to a strategy that would have the same\ndelay D3min = 595 frames for all clients (dotted line).\nE. Unequal delay penalties\nSome applications may necessitate to devise a scheduling strategy\nwith unequal delay penalties, where some clients are considered as\nprioritized compared to others. This can be achieved by minimizing\na weighted standard deviation of the delay penalties. In this case,\nthe delay distribution has to be chosen according to the following\noptimization problem:\nDopt = argmin\nD\nE\nh\n(wT (\u2206\u2212 \u00b5)2\ni\n(15)\nunder the condition that SlD(t) \u2264 C(t) \u2200l, 1 \u2264 l \u2264 L, i.e., all the\ntraces are schedulable from Eq. (1). The weights w = [w1, . . . , wL]\nrepresent positive weights that permit to control the distribution of the\npenalties among the L layers. A relatively high value of the weight\nwl typically constrains the delay Dl to be close to the minimal delay\nDlmin.\nDepending on the weight distribution, it might be difficult to\nfind the optimal solution to the problem of Eq. (15) without using\nan exhaustive search over the (reduced) space of possible delay\nvalues. We however propose a low complexity algorithm that finds\nthe optimal playback delay set Dopt. It is based on the a priori\ninformation about the structure of the optimal solution that sets the\ncost function in Eq. (15) to 0. It can be reached only when\n\u2206l =\nwk\nwl\n\u2206k, (16)\n\u2200k, l, 1 \u2264 k \u2264 L, 1 \u2264 l \u2264 L. This imposes that the delay\npenalty takes the form \u2206l = K/wl,\u2200l, where K is a constant.\nTherefore, solving the optimization problem of Eq. (15) is equivalent\nto find to smallest value of K such that the aggregate trace SLD(t)\nis schedulable. In other words, one has to find the smallest K such\nthat verifies\nLX\nl=1\n\u039bl\n\u201e\nt\u2212Dlmin \u2212\nK\nwl\n\u00ab\n\u2264 C(t),\u2200t. (17)\nThe search algorithm, given in Algorithm 3, simply increases K\ngradually, until the aggregate trace is schedulable. At each iteration,\nit updates the playback delays, constructs the aggregate source trace,\nand checks the schedulability condition. If the resulting trace is\nschedulable, the algorithm stops. Otherwise, the value of K is\naugmented by \u03b4, and the process is repeated until the resulting trace\nis schedulable.\nNote that the algorithm may find a sub-optimal solution to the\nproblem of Eq. (15) due to granularity of the delay increments.\nHowever, the complexity is drastically reduced compared to a full\nsearch algorithm. If all the weights are equal, we obviously get back\nto the the fair model of the previous section. However, we have seen\nthat in the fair case we only need to test O(log(trace length))\npossibilities, where each test can be performed in polynomial time.\nAlgorithm 3 always performs O(trace length) such tests.\n7Algorithm 3 Dh =\n`\nC(t), {\u039bl(t)}, w, \u03b4\n\u00b4\n1: Dlh \u21d0 D\nl\nmin , 1 \u2264 l \u2264 L.\n2: Construct the trace using delays Dlmin:\n3: SLDh(t)\u21d0\nLP\nl=1\n\u039bl\n`\nt\u2212Dlmin\n\u00b4\n4: while SLDh(t) \u0002 C(t), \u2200t do\n5: increase the delays according to the assigned weights:\n6: for l = 1 to L do\n7: Dlh \u21d0 D\nl\nh +\n\u03b4\nwl\n8: end for\n9: bound delays such that there are non-decreasing:\n10: for l = L\u2212 1 downto 1 do\n11: Dlh \u21d0\n`\nmin(Dlh, D\nl+1\nh\n\u00b4\n12: end for\n13: construct new trace:\n14: SLDh(t)\u21d0\nLP\nl=1\n\u039bl\n`\nt\u2212Dlh\n\u00b4\n15: end while\n16: for l = 1 to L do\n17: Playback delays are integers (in frame units)\n18: Dlh \u21d0 \u2308D\nl\nh\u2309\n19: end for\nWe validate the proposed algorithm on a composite sequence,\nencoded using the MoMuSys MPEG-4 FGS reference codec [17].\nWe run 100 tests where the channel is a piecewise CBR channel\nwith rates chosen randomly in {128kbps, 256kbps, 384kbps}, and\nrandom lengths for each constant rate segment. We set the weights\nto w = {1, 100, 1}, which means that the playback delay for layer 2\nin the optimal playback delay set should be kept as close as possible\nto its minimum playback delay. In our results, the optimal playback\ndelay for layer 2 is indeed always within at most 2 frames of D2min,\nthus validating our weighted metric function, as expressed in Eq.\n(15). In all the cases, the cost function is minimal. Note that this\nmight not be always the case for the algorithm with reduced search\nspace proposed in Section III-C, since the bounds of the delay interval\nmight not allow to find the optimal solution in the sense of Eq. (15)\nthat does not include an explicit minimization of the average playback\ndelay. Finally, the average number of potential solutions tested by the\nproposed algorithm was 1.59\u00b7103 for the aforementioned experiment,\ncompared to 1.82\u00b7107 for the generic full search algorithm in Section\nIII-C. The considerations on the structure of the optimal solution\nspace thus permits a dramatic reduction of the computation time.\nIV. MINIMUM RECEIVER BUFFER\nA. \u03b2-optimal sending rate\nOnce playback delays are given, the server still has the flexibility\nto choose the packet scheduling policy under the constraints given\nby the channel. The packet scheduling policy typically influences\nthe dynamic behavior of the receiver buffer. In particular, we are\ninterested in defining the sending rate at the server, which minimizes\nthe buffer occupancy at all times t at the receiver in a given streaming\nscenario represented by (C(t), S(t),D). At the same time, the\nsending rate shall ensure that the receiver buffer does not experience\nany starvation in order to guarantee a smooth video playback. This\nsending rate is called \u03b2-optimal and we denote it as X\u03b2(t).\nIf condition of Eq. (1) is verified, there exists a family of sending\nrates X such that each X(t) \u2208 X satisfies both Eqs. (2) and (3).\nIn these cases, the video can be played back at the receiver after\nD time units without experiencing any buffer underflow. The \u03b2-\noptimal sending rate is the scheduling solution that minimizes the\nbits C(t)=X?(t)\nSD(t)\nD T+D\nC(T+D) = S(T+D)\nbits C(t)\nSD(t)\nD T+D\nC(T+D) > S(T+D)\nX?(t) = ?\nFig. 5. Left: Limiting case with X\u03b2(t) = C(t). Right: The set of\nsending traces X(t) that verifies Eqs. (2) and (3) generally contains multiple\ncandidates.\nbuffer occupancy at the receiver. It can be written as:\nX\u03b2(t) = arg min\nX(t)\u2208X\n(B(t) = X(t)\u2212 SD(t)) ,\u2200t, (18)\nwhich means that, for any sending rate X(t) \u2208 X \\X\u03b2(t), we have:\nX\u03b2(t) \u2264 X(t),\u2200t (19)\nUsing the formalism from [4], X\u03b2(t) is the smallest sending rate\nthat satisfies the following conditions:\n\u2022 X(t) is a causal flow, i.e., X(t) = 0 for t \u2264 0.\n\u2022 the flow X(t) is constrained by an arrival curve \u03c3(\u00b7) that reflects\nthe channel availability constraints. This means that for all t \u2265 0\nand for all s \u2208 [0, t], X(t) \u2212 X(s) \u2264 \u03c3(t \u2212 s). There is no\nfurther constraint imposed by the network.\nWhen the server can prefetch data from any future frame at any time,\nand when the playback delay is chosen such that there is no buffer\nunderflow at the receiver, there exists a minimal solution to the above\nset of constraints. It is given by:\nX\u03b2(t) = (S \u2298 \u03c3)(t\u2212D) (20)\nHere \u2298 denotes the Min-Plus deconvolution of two wide-sense\nincreasing functions f and g, defined as:\n(f \u2298 g)(t) = sup\nu:u\u22650\n{f(t+ u)\u2212 g(u)} (21)\nThe interested reader is referred to [5] for more details on the\nnetwork calculus formalism that is used for proving the existence of\nthe minimal sending trace.\nIn the rest of this section, we propose an algorithm that offers an\nintuitive and tractable solution for computing the \u03b2-optimal sending\nrate for non-scalable streams. This algorithm is a generalization of\nthe algorithm presented in [1]. We then show that a jointly \u03b2-optimal\nsending trace exists also in the case of scalable streams, and we\npropose a method to compute the sending rate that minimizes the\nbuffer occupancy for a set of heterogeneous receivers.\nB. Single layer streams\nWe provide an intuitive algorithm for computing the \u03b2-optimal\nsending rate for single layer streams. Let us consider first a limiting\ncase where the channel has to be fully used to transmit the complete\nbitstream, i.e., C(D + T ) = SD(D + T ). In this case illustrated in\nFigure 5 (left), the set of schedulable sending traces only contains\none solution. Any sending rate for which there exists some t where\nX(t) < C(t) implies that X(D + T ) < SD(D + T ), where T is\nthe duration of the video sequence. This violates the condition of Eq.\n(2). Hence the only valid sending rate function is also the solution\nthat minimizes the buffer occupancy for all times t. It is given by\nX\u03b2(t) = C(t).\n8Algorithm 4 X\u03b2 = V RS (C(t), SD(t)))\nRequire: SD(t) \u2264 C(t),\u2200t\n1: X\u03b2(t) \u21d0 C(t), for all t. The sending trace is computed as a\nreduced channel trace.\n2: t\u21d0 0\n3: while t \u2264 T +D do\n4: if \u2204t\u2032 \u2265 t s.t. X\u03b2(t\u2032) = SD(t\u2032) then\n5: Reduce the channel down by X\u03b2(t)\u2212 SD(t)) bits.\n6: for all \u03c4 in [t, T +D] do\n7: X\u03b2(\u03c4 )\u21d0 X\u03b2(\u03c4 )\u2212X\u03b2(t) + SD(t)\n8: end for\n9: t\u21d0 t+ 1\n10: else\n11: The curves touch, no reduction at this step.\n12: tnew \u21d0 sup\u03c4>t {\u03c4 |X\u03b2(\u03c4 ) = SD(\u03c4 )}\n13: t\u21d0 tnew\n14: end if\n15: end while\nIn the general case where C(T+D) > SD(T+D), several sending\ntraces represent valid scheduling solutions that satisfy the condition\nof Eq. (1), as illustrated in Figure 5 (right). In order to compute the\n\u03b2-optimal sending rate, we make the following observations. First,\nX\u03b2(t) obviously shall fulfill the conditions of Eqs (2) and (3) that\ndefine the schedulable solutions. In order to minimize the buffer\noccupancy B(t), \u2200t, X\u03b2(t) also needs to follow SD(t) as closely\nas possible. This is equivalent to keeping the sending rate as small\nas possible, but still to send enough data to avoid buffer starvation\nunder the constraints imposed by the channel bandwidth. Finally, we\nknow from the limiting case presented above that, whenever there\nexists a time \u03c4 such that SD(\u03c4 ) = C(\u03c4 ), the \u03b2-optimal sending rate\nneeds to be equal to C(t) up to \u03c4 . Therefore, it becomes clear that\nB(t) can be minimized for all times t if and only if data is sent at\nthe latest possible instant in time such that all data still arrive on time\nfor decoding. We can thus eliminate the early sending opportunities\noffered by the transmission channel, and reduce the channel to the\nsending opportunities that are necessary to transmit all the data before\ntheir decoding timestamps.\nThe \u03b2-optimal sending rate can now be computed by the Variable\nRate Smoothing (VRS) algorithm given in Algorithm 4. The algo-\nrithm operates in the cumulative domain, starting at time t = 0. It\nfirst sets the sending trace to be equal to the channel trace C(t),\n\u2200t. Then, it iteratively checks for t = 0 . . . T +D whether there is\nequality at any future time instant t\u2032 between the sending trace and\nthe delayed source trace SD(t). In this case, the situation is similar\nto the limiting case presented above, and the sending rate has to be\nequivalent to the channel rate up to the time instant t\u2032 = t. However,\nif the sending trace is strictly larger than the delayed source trace\nfor all time instants t\u2032 > t, the sending trace at all time instants\nt\u2032 > t is reduced by the difference between the sending trace and the\ndelayed source trace at time t. This operation basically consists in\neliminating the early transmission opportunities, which would results\nin wasting buffer resources. It is equivalent to translating the sending\ntrace curve down by X\u03b2(t) \u2212 SD(t) for all t\u2032 > t. Note that the\ncomplexity of Algorithm 4 is O(T + D), where the worst case is\nachieved if s(t\u2212D) < c(t), \u2200t.\nAn illustration of the VRS algorithm is presented in Figure 6,\nwhere the channel trace C(t) is linear and the delayed source trace\nSD(t) is piecewise linear. At time t = 0, X\u03b2(t) and SD(t) do\nnot touch. This will remain the same up to t1. This means that up\nto t1, the derivative of SD(t) is certainly never larger than that of\nX\u03b2 , or equivalently that the instantaneous sending rate is not smaller\nthan the delayed source rate. The algorithm sets the sending trace\nto SD(t) up to time t1. The sending trace computed at time t = t1\ntouches the source curve at time t2new. This means that, in the interval\n[t1, t2new], the derivative of SD(t) is at times larger than the derivative\nof the sending trace of X\u03b2(t). In other words we have reduced the\nsituation in this interval to the limiting case and we have to use all\nthe channel bits in order to transmit the needed data. The algorithm\ndoes not reduce the sending trace for t in [t1, t2new]. After t = t2new,\nthe sending trace can again be reduced to the delayed source trace.\nUsing the time-inversion technique outlined in [5], it can finally be\nchecked that the resulting sending rate in this example is the same\nas the one resulting from Eq. (20) where the arrival curve is set to\n\u03c3(t) = dC(t)\ndt\n\u00b7 t.\nOnce the optimal sending trace has been computed, the buffer\noptimal scheduling strategy simply consists in sending data in the\nincreasing order of their decoding deadline while respecting the\nconstraints given by the sending trace. If one does not respect this\norder, some packets are sent in advance, which can only contribute to\nincrease the buffer occupancy. Equivalently, the optimal scheduling\nof the packets can also be achieved by scheduling packets as late as\npossible [9], without pre-computing the buffer optimal sending trace.\nThis last opportunity scheduling policy basically consists in reversing\ntime, starting from t = T+D to t = 0. Then it schedules at each time\ninstant t as many of the packets with the largest decoding deadlines in\nsD(t) as the channel c(t) permits it. This solution jointly computes\nthe buffer optimal scheduling, and the optimal sending trace. It is\nhowever based on reversing the time axis after t = T + D, which\nmight present limitations in some practical systems.\nFinally, Figure 7 illustrates the \u03b2-optimal sending rate: the used\nvideo trace is formed of 2 GOPs of the MPEG-4 encoded Foreman\nsequence. The channel is a constant bit rate (CBR) channel. The\nleft column depicts the source rate s(t), channel rate c(t) and\nthe illustrated sending rate. The middle column shows the same\ntraces in the cumulative domain, and the right column shows the\nbuffer occupancy as a function of time: B(t) = X(t) \u2212 SD(t).\nThe top row shows one valid but sub-optimal sending trace. Note\nthat supt (X(t)\u2212 SD(t)) = 21264 > 11468 bits (see top-right).\nThe bottom row shows the \u03b2-optimal scheduling policy, where the\nsending rate follows the source rate whenever possible. Whenever\nsD(t) > c(t), data is sent at the latest possible opportunity, thus\nminimizing the buffer occupancy for all t. The maximum amount of\nbuffering needed is 11468 bits (see bottom-right).\nC. Scalable streams\nIn this section, we consider the case of scalable streams and we\nshow that there exists a scheduling strategy that jointly minimizes\nthe buffer occupancy Bl(t) for each each receiver group Rl and\nat all times t. Then we propose a scheduling algorithm that offers\na practical solution to build the sending trace X\u03b2(t) that is jointly\n\u03b2-optimal for multiple receivers.\nWe consider that a set of source traces S =\n\u02d8\n\u039bl(t)\n\u00afL\nl=1\n, represent-\ning L additive hierarchically encoded layers are sent simultaneously\nto multiple receivers Rl, 1 \u2264 l \u2264 L through a joint bottleneck\nchannel given by the cumulative rate C(t). We further consider a set\nof non-decreasing playback delays D =\n\u02d8\nDl\n\u00afL\nl=1\nthat are used by\nthe different receiver groups. Each receiver in the group Rl starts\nconsuming the media layers 1 to l of the hierarchically encoded\nstream after an initial playback delay Dl. The aggregate source trace\nthat has to be sent over the channel in order to ensure a smooth\n9bits\nt\nC(t)\nSD(t)\nD\nbits\nSD(t)\nDT+D\nt = 0 t = t1\nt\nT+Dt\n1\nt1\nbits\nSD(t)\nD\nt = T+D\nt\nT+Dt\n1 t2new\nC(t)\nC(t)\nt2new\nFig. 6. Illustration of the VRS Algorithm. In order to minimize the buffer occupancy, the sending trace is reduced to the delayed source trace when the\nchannel rate is superior to the source rate.\n0 20 40 60\n0\n\u03b2\n-\no\npt\nim\nal\n \nsc\nhe\ndu\nlin\ng\n0 20 40 60\n0\nPlayout, channel and sending\ntraces (cumulative domain)\n0 20 40 60\n0\nBuffer occupation\n0 20 40 60\n0\n5\n10\n15\nG\nen\ner\nic\n \nsc\nhe\ndu\nlin\ng\ntime in frames (30 fps)\n[kb\nit]\n0 20 40 60\n0\n50\n100\n150\n200\ntime in frames (30 fps)\n0 20 40 60\n0\n5\n10\n15\n20\ntime in frames (30 fps)\nsD(t)\nc(t)\nx\u03b2(t)\nSD(t)\nC(t)\nX\u03b2(t)\nB(t)\nsD(t)\nc(t)\nx(t)\nSD(t)\nC(t)\nX(t)\nB(t)\n5\n10\n15\n[kb\nit]\n50\n100\n150\n200\n5\n10\n15\n20\nPlayout, channel and sending\ntraces (temporal domain)\n[kb\nit]\n[kb\nit]\n[kb\nit]\n[kb\nit]\nFig. 7. \u03b2-optimal scheduling outperforms any generic scheduling algorithm with respect to receiver buffer occupancy.\nplayback by all decoders is constructed as:\nSlD(t) =\nlX\ni=1\n\u039biDi(t), (22)\nwhere \u039biDi(t) is the cumulative function of \u03bb\ni\nDi(t), the source trace\nof layer i, delayed by Di. We assume here that D is chosen such\nthat the full stream is schedulable, i.e. that SlD(t) \u2264 C(t), \u2200t, \u2200l. It\nis important to note here that the cumulative rate given by Eq. (22)\nis in fact larger than the rate used by the decoder. When a receiver\nin Rl starts playing the stream at time Dl, all the source traces up\nto l are drained simultaneously from the receiver buffer. Thus the\nplayout trace at a receiver in Rl, which represents the number of\nbits consumed up to time t, is given as:\nSlDl(t) =\nlX\ni=1\n\u039biDl(t). (23)\nThese different traces are illustrated in Figure 8. Note that we have:\nXl(t) \u2265 SlD(t) \u2265 S\nl\nDl(t),\u2200t, (24)\nwhere the first inequality is due to the schedulability condition, and\nthe second inequality results from the construction of the playout\ntrace, with Di \u2264 Di+1. There are in general several valid sending\ntraces Xl(t) for scheduling the layers 1 to l under a given set of\ndelay and source trace constraints. We denote this set of valid traces\nas X l = {Xl(t)}. We are interested in finding the trace Xl\u03b2(t) \u2208\nX l that minimizes the buffer occupancy all the receivers Rl for all\ntimes t. It corresponds to the sending trace that minimizes Bl(t) =\nXl(t)\u2212SlD(t), \u2200t. The cumulative sending trace is built on l additive\nlayers, and we denote the sending trace of layer l as Y l(t), withPl\nk=1 Y\nk(t) = Xl(t). Similarly, we denote the \u03b2-optimal sending\ntrace of layer l as Y l\u03b2(t).\nbit\nD1 T+DlT+D\n1\nDl\nFig. 8. Illustration of the aggregate source trace Sl\nD\n(t) and the play-out\ntrace at receiver Rl, SlD(t), along with one of the possible sending traces\nXl(t) .\nFrom the previous section, we know that if we only consider one\nresolution level l, Xl\u03b2(t) exists. It can be computed by Algorithm\n4 for every resolution level l. In a scenario where clients might\nsubscribe only to a subpart of this aggregated stream for a resolution\nlevel k < l, such a scheduling would however be suboptimal in terms\n10\nof buffer occupancy for the low resolution clients. In other words, if\nthe sending rate is generated from the stream at resolution l without\nexplicitly considering the lower layers, we can a priori not provide\nany guarantee on the buffer occupancy at receivers Rk, k < l that\nconsume only the lower layers. We are rather interested in finding the\nsending trace that minimizes the buffer occupancy at all times t for all\nreceivers simultaneously, if such a solution exists. We prove below an\nimportant proposition that says that a joint \u03b2-optimal scheduling for\nmultiple receivers actually exists, and that the solution Xl\u03b2(t) \u2208 X l\ncan actually be constructed on the \u03b2-optimal traces for layers k < l.\nProposition 1: If SLD(t) \u2264 C(t), \u2200t, then there exists a scheduling\npolicy that is jointly \u03b2-optimal for all receivers Rl, 1 \u2264 l \u2264 L that\nrespectively consume the layers 1 to l after an initial playback delay\nDl.\nProof:\nGiven C(t) and SlD(t), we know that Xl\u03b2(t) exists, for any l taken\nindividually. We want to show that there exists a valid sending trace\nY l\u03b2(t) for scheduling layer l, when streams at resolution l and l\u2212 1\nboth minimize the buffer occupancy for the respective client sets.\nSuch a trace can be written as:\nY l\u03b2(t) = X\nl\n\u03b2(t)\u2212X\nl\u22121\n\u03b2 (t). (25)\nIt is a valid sending trace for layer l iff\n\u039blDl(t) \u2264 Y\nl\n\u03b2(t) \u2264 C(t)\u2212X\nl\u22121\n\u03b2 (t),\u2200t. (26)\nIn other words, the sending trace for layer l has to be large enough\nto ensure a smooth playback after a delay Dl. At the same time,\nit has to be small enough to respect the channel constraints, once\nthe sending trace Xl\u22121\u03b2 (t) has been allocated already. As X\nl\n\u03b2(t) is\nschedulable by hypothesis, we have Xl\u03b2(t) \u2264 C(t). We can therefore\nwrite Xl\u03b2(t)\u2212Xl\u22121\u03b2 (t) \u2264 C(t)\u2212X\nl\u22121\n\u03b2 (t) Combined with Eq. (25\n), it leads to proving the second part of Eq. (26).\nThe schedulability of Xl\u03b2(t) also induces that the data of layer l\nare present on time at the decoder. In other words, there exists a set\nof sending traces Xl\u22121(t) for the data of layers 1 to l\u2212 1 such that\n\u039blDl(t) \u2264 X\nl\n\u03b2(t)\u2212X\nl\u22121(t),\u2200t.\nIn particular, since by definition Xl\u22121\u03b2 (t) \u2264 X\nl\u22121(t), we have\n\u039blDl(t) \u2264 X\nl\n\u03b2(t)\u2212X\nl\u22121\n\u03b2 (t),\u2200t,\nor equivalently\n\u039blDl(t) \u2264 Y\nl\n\u03b2(t),\nwhich proves the first part of Eq. (26).\nTherefore, there exists a valid sending trace that minimizes jointly\nthe buffer occupancy for receivers sets Rl\u22121 and Rl. By recursion,\nwe can construct the \u03b2-optimal solutions as Xl\u03b2(t) =\nPl\nk=1 Y\nk\n\u03b2 (t).\nMoreover, we have the following corollary.\nCorollary 1: The optimal sending trace Y l\u03b2(t) is the minimal valid\nsending trace for layer l on a channel of bandwidth C(t)\u2212Xl\u22121\u03b2 (t),\nwhen the playback delay is set to Dl.\nProof: We prove the corollary by contradiction. Assume that\nthere exists a trace Yl(t) such that Yl(t) < Y l\u03b2(t) as some time t.\nIn this case, we have Xl(t) = Xl\u22121\u03b2 (t) + Y\nl(t) \u2264 Xl\u03b2(t), which\ncontradicts the assumption on the optimality of Xl\u03b2(t). Y l\u03b2(t) is\ntherefore the minimal sending trace for layer l.\nBased on Proposition 1 and Corollary 1, we can build an iterative\nalgorithm to build the joint \u03b2-optimal sending rate for any layer l\nby greedily building the \u03b2-optimal sending rate one layer at a time,\nstarting at the lowest one. In particular, we have\nXl\u03b2(t) =\nlX\ni=1\nY i\u03b2(t), l > 1 (27)\nand Y 1\u03b2 (t) = X1\u03b2(t). The sending rate can be computed for each layer\niteratively starting from layer 1 by the VRS algorithm. It computes\nthe sending trace that corresponds to \u039bl\nDl\n, the bits of layer l that\nare decoded after a playback delay Dl. The bandwidth constraints\nare updated iteratively, as the bandwidth used by the lower layers is\nremoved from the channel capacity. Therefore, we have\nCl(t) = Cl\u22121(t)\u2212 Y l\u22121\u03b2 (t),\u22001 < l \u2264 L, (28)\nwhere Cl(t) corresponds to the part of the channel that is available\nto schedule bits from layer l, and C1 = C(t). Once the optimal\nsending traces Y i\u03b2(t) have been computed for each layer l, the\npacket scheduler proceeds by sending the data of each layer in\nthe increasing order of the decoding deadlines, while respecting\nthe different sending traces. For each layer, the scheduler proceeds\nsimilarly to the scheduler for single layer streams.\nNote that another strategy could be proposed to reach the buffer\noptimal sending traces. It consists in reverting the time axis, starting\nfrom t = T +Dl to t = 0. Then the packets of each layer are sent at\nthe latest moment for correct decoding, while respecting the channel\nbandwidth c(t). As the layer 1 is decoded with the smallest playback\ndelay, it is scheduled first. Other layers are scheduled iteratively\nunder the constraints given by the remaining channel bandwidth cl(t).\nSimilarly to the case of single layer streams, this solution guarantees\nthe lowest buffer occupancy at the decoder, without the explicit\ncomputation of the optimal sending traces. From Proposition 1, it\nalso leads to the jointly optimal policy for all the resolution levels,\nor all the clients Rl.\nWe illustrate the resulting performance of this iterative algorithm in\nFigure 9: it shows a constant bitrate channel and the playout rates of 2\nGOPs of the MPEG-4 FGS encoded Formeman sequence, at receiver\nR1 (layer 1 only) and R2 (layers 1 and 2), see left. Playout begins at\nall the receivers after D=20 frames. The same scenario is shown in\nthe cumulative domain (see middle). Only the aggregate playout trace\nat R2 (i.e. \u039b1(t\u2212D)+\u039b2(t\u2212D)) is shown in blue. The green curve\nshows the \u03b2-optimal sending rate for the aggregate playout curve and\nthe considered channel, as given by the VRS Algorithm. It is thus the\n\u03b2-optimal sending rate for receivers in the set R2. Figure 9-right: on\nthe one hand, the solid and dashed blue curves show the sending rates\nfor layer 1 data and layer 2 data respectively, in the case where the\n\u03b2-optimal sending trace is computed from the aggregate playout trace\nat R2. On the other hand, the dashed red curve shows the \u03b2-optimal\nsending rate for R1, X1\u03b2(t), obtained from a \u03b2-optimal scheduling\nof layer 1 over the channel C(t). It can be noticed that data for\nlayer 1 is only transmitted shortly before the playout deadline, thus\nreducing the buffer occupancy at R1. In this scenario, the solid red\ncurve shows the sending rate of layer 2 over the remaining bitrate\nC(t)\u2212X1\u03b2(t). Note that in both cases, all data that is sent meets their\ndeadline, and in both cases, the two respective sending rates add up\nto X\u03b2(t) (green curve), which is the \u03b2-optimal sending rate for R2.\nIn the same scenario, Figure 10 finally shows the evolution of\nthe buffer occupancy at receivers R1 (left) and R2 (right) if joint\n\u03b2-optimal scheduling is used (top) and if \u03b2-optimal scheduling is\ncomputed only on the 2 layers stream (bottom). The minimum buffer\noccupancy at R2 is achieved in both cases, however the minimum\nbuffer occupancy at R1 is only achieved in the first case (top-left).\nThe joint \u03b2-optimality is achieved through the fact that receivers that\nsubscribe to higher layers buffer less data from lower layers in the\nfirst case, and more data from higher layers. However, the buffer\ncontains the same total amount of data in both scheduling choices.\nFinally, it is important to note that joint playback delay and buffer\noptimization can be achieved with the algorithms proposed in the Sec-\ntions III and IV. The delay optimization does not put assumptions on\n11\n0 10 20 30 40 50 60 70 80 90\n0\n50\n100\n150\n200\n250\n300\n350\ncumulative domain\ntime in frames (30 fps)\n[kb\nit]\n0 10 20 30 40 50 60 70 80 90\n0\ntime in frames (30 fps)\n0 10 20 30 40 50 60 70 80 90\n0\n2\n4\n6\n8\n10\n12\n14\n16\ntemporal domain\ntime in frames (30 fps)\n[kb\nit]\ncumulative domain\nSending rate for layer 1 \u2212 not joint \u03b2\u2212optimal\nSending rate for layer 1 \u2212  joint \u03b2\u2212optimal\nX\n \u03b2  (t)\nSending rate for layer 2 \u2212 not joint \u03b2\u2212optimal\nSending rate for layer 2 \u2212  joint \u03b2\u2212optimal\n\u039b\n1(t\u2212D)+\u039b2(t\u2212D)\nC(t)\nX\u03b2(t)\n\u03bb\n1\n\u03bb\n1(t\u2212D)+\u03bb2  (t\u2212D)\nc(t)\n(t\u2212D)\n50\n100\n150\n200\n250\n300\n[kb\nit]\nFig. 9. Validation of the \u03b2-optimal scheduling scheduling algorithm. Left: the traces of two layers and a CBR channel in the temporal domain, playout starts\nafter 20 frames. Middle: The channel trace and the aggregate playout trace for both layers in the cumulative domain. The green curve shows the sending trace\nthe minimizes the buffer occupancy at R2, as given by the VRS algorithm. Right: We achieve the \u03b2-optimal sending trace for layer 1, without sacrificing the\n\u03b2-optimality of the aggregate sending trace for both layers 1 and 2.\nlayer 1 data\nlayer 1 data\nlayer 2 data\nlayer 2 data\nall data\nall data\n0            20          40          60          80 0            20          40          60          80\n0            20          40          60          80 0            20          40          60          80\ntime in frames (30fps)\nb\ne\nta\n-o\np\nti\nm\na\nl \nfo\nr \nR\n2\njo\nin\ntl\ny\n b\ne\nta\n-o\np\nti\nm\na\nl \nfo\nr\n  \n  \n  \n  \n  \nR\n1\n a\nn\nd\n R\n2\nBuffer Occupation at R1 Buffer Occupation at R2\n  \n  \n  \n  \n  \n1\n0\n  \n  \n  \n 2\n0\n  \n  \n  \n3\n0\n  \n  \n  \n4\n0\n  \n \ntime in frames (30fps)\n[k\nb\nit\n]\n  \n  \n  \n  \n  \n1\n0\n  \n  \n  \n 2\n0\n  \n  \n  \n3\n0\n  \n  \n  \n4\n0\n  \n \n[k\nb\nit\n]\n  \n  \n  \n  \n  \n1\n0\n  \n  \n  \n 2\n0\n  \n  \n  \n3\n0\n  \n  \n  \n4\n0\n  \n \n[k\nb\nit\n]\n  \n  \n  \n  \n  \n1\n0\n  \n  \n  \n 2\n0\n  \n  \n  \n3\n0\n  \n  \n  \n4\n0\n  \n \n[k\nb\nit\n]\nFig. 10. Buffer evolution in \u03b2-optimal scheduling scenarios.\nthe actual sending traces,it only considers schedulability conditions.\nSimilarly, when playback delays are selected, the buffer optimization\nsimply consists in finding the smallest sending trace among the set\nof valid traces. Both problems can be solved sequentially, and the\nresulting solution jointly optimizes the playback delay, and the buffer\noccupancy.\nV. CHANNEL-ADAPTIVE STREAMING\nA. Source rate adaptation\nIn the previous sections, we have provided an analysis of the\nplayback delay and buffer occupancy, as well as joint optimization\nstrategies. These solutions rely on the assumption of perfect knowl-\nedge about the bottleneck channel bandwidth. They provide upper-\nbounds on the performance of common practical systems, where the\ncomplete channel trace is usually not known at the server. When\nthe actual channel bandwidth does not exactly correspond to the\ntrace that is used for packet scheduling, the server may not be\nable to send all packets according to their computed schedules. It\nhas therefore to take actions such as reduction in the source rate,\nto adapt to temporary bandwidth reduction. Rate adaptation can be\nperformed efficiently on scalable streams by dropping packets from\nthe higher layers. If such mechanisms are used carefully, the quality\nof service is not significantly affected. Another solution is to devise\n       Known for slot k:\n - AVG_RATE c\n - rate = estimated channel rate in slot k-1\n - feedback = new rate observation c\n - scheduling look_ahead\n~\nL\nFig. 11. Rate adaptation algorithm\na conservative scheduling approach that considers lower-bounds on\nthe channel bandwidth. The authors in [18] for example compute\nthe playback delay for a single stream over a stochastic channel by\nderiving a channel trace that lower bounds all possible realizations\nof the channel. Rate adaptation generally reaches a higher average\nquality than conservative scheduling methods, at the price of possibly\nhigher quality variations for the clients that subscribe to the highest\nresolution streams.\nWe assume that the server knows some channel statistics such as\nthe average bottleneck bandwidth c\u00af. The playback delays and the\nsending traces are initially computed based on a constant bit rate\nchannel of rate c\u00af. This results in a complete schedule that determines\nwhich packet (and which layer) has to be sent at each time instant\nt, in an ideal scenario. During the broadcasting session, the server\nmonitors the state of the channel, and the sending rate can be adapted\nin case the available bandwidth becomes insufficient to be able to\nrespect the original packet schedule.\nWe propose below a sample system based on a simple rate\nadaptation algorithm, and we show that rate adaptation still permits\nto keep the buffer occupation close to minimum, and that playback\n12\ndelays close to the ideal values can be achieved, at the price of only\nminor and controlled PSNR degradations.\nB. System description\nWe have tested the rate adaptation scheme on a sample system.\nThe scalable video stream is segmented such that data from different\nframes and different video layers are fed into different RTP packets.\nThe video stream is sent simultaneously to 3 clients R1, R2 and\nR3 that decode layers up to 1, 2 and 3 respectively. The average\nchannel rate has been set to 32 kbytes/sec, and we use a NISTNet\n[19] network emulator to limit the bandwidth on the server-client\nbroadcast link according to a given random bandwidth trace, which\nis unknown at the server.\nThe server sends the stored layered stream according to the\nscheduling strategy computed with a CBR channel of c\u00af = 32 kBps\nand a given set of target playback delays D. At each discrete time\nt the server transmits RTP packets according to the ideal scheduling\nplan, when it is possible. At the same time, the server updates the\nchannel rate estimate as well as the scheduling look-ahead after each\nsecond. The approximate channel rate is computed from the round-\ntrip time estimated that are sent in the client RTCP receiver reports,\nas c\u02dc = packet length\u22172\nRTT\n, where packet_length is the average\nlength of packets that have been sent during the previous slot. The\nscheduling look-ahead represents the difference between the actual\nscheduling, and the scheduling that has been pre-computed with\nan ideal channel. In other words, it measures the advance that the\nscheduler has taken compared to the pre-computed schedule.\nBased on these parameters, the rate adaptation algorithm presented\nin Figure 11 adapts the sending rate according to a AIMD (additive\nincrease multiplicative decrease) policy. The additive step size is\ndependent on whether the current rate is above or below the targeted\naverage rate, and we have chosen the following factors:\n\u2022 a1 =\nc\u00af\nframerate\n, if c\u02dc > c\u00af\n\u2022 a2 = 2 \u00b7\nc\u00af\nframerate\n, if c\u02dc \u2264 c\u00af .\nThe choice of having a lower increment if the estimated rate is above\naverage, leads the server to taking advantage carefully of the available\nrate, while trying to avoid over-estimation. The order of packets is\nmaintained even if the rate has to be adapted. The sending rate is\nthus augmented by advancing faster on the pre-defined schedule, and\nresulting in a positive scheduling look-ahead value.\nWhen the sending rate has to be reduced, we use a multiplicative\ndecrease policy with a factor m = 0.96. However, if a decrease\noccurs when the rate is above the average rate, the rate is immediately\nclipped to the average rate. The choice of these parameters is based\non empirical data and depends on the channel statistics. If the\ntransmission is ahead of schedule, the look-ahead is used to absorb\nthe temporary rate decay and the sending rate is simply reduced, while\nthe order of the packets is maintained. If however, the transmission\nis running behind the original schedule, packets of the highest layer\nare not transmitted and simply dropped.\nC. Experimental results\nThe performance of the above sample system are now analyzed\nthrough experiments. We have used the same composite video se-\nquence as proposed before, that has been encoded in QCIF at 30\nframe per second with the MPEG-4 FGS encoder. The set of target\ndelays was set to D = {D1 = D2 = 98, D3 = 381}.\nFigure 12 shows the number of layers that are transmitted by the\nrate-adaptive server, as well as the evolution of the scheduling look-\nahead as compared to the pre-computed schedule. We see that at time\ninstant t = 23 sec, the channel estimate is low and the scheduling\n0 5 10 15 20 25 30 35 40\n\u221220\n0\n20\n40\n60\n80\n100\nsc\nhe\ndu\nlin\ng \nlo\nok\n\u2212a\nhe\nad\n2\n3\ntime [s]\nla\nye\nrs\nFig. 12. Scheduling look-ahead compared to the pre-computed schedule\n(solid line) and number of transmitted layers (dashed line) according to the\nrate adaptation algorithm.\n0 200 400 600 800 1000 1200\n0\n0.5\n1\n1.5\n2\n2.5\nx 104 Reconstructed trace at R\n3\ntime in frames (30 fps)\nby\nte\ns\nFig. 13. Playback trace at R3 expects to decode the complete stream (3\nlayers).\nlook-ahead is not sufficient to continue sending all layers. So the\nserver stops transmitting layer 3 in order to avoid further congestion\nuntil both the channel rate and the scheduling look-ahead increase\nagain. Finally Figure 13 shows the decodable received source trace at\nclient R3 that subscribes to the complete stream, and starts decoding\nafter a playback delay D3, equivalent to 381 frames. It can be seen\nthat approximately 3 seconds worth of layer 3 data are missing.\nThis correspond to the the amount of layer 3 data that was not\ntransmitted due to the server\u2019s rate adaptation. Dropping the highest\nlayer temporarily from the broadcast leads to a decrease of less than\n0.5dB in average PSNR compared to the complete reception of layer\n3. However, if a conservative scheduling approach is chosen in such\na scenario, the layer 3 is not transmitted at all. The average quality\nis therefore higher with the rate adaptation solution, at the price of\nquality variations.\nWe analyze in Figure 14 the influence of the rate adaptation on\nthe playback delays that are necessary to ensure smooth decoding at\nthe receivers. The target playback delays that are pre-computed in\nan ideal streaming scenario are D = {D1 = D2 = 98, D3 = 381}.\nThese delays are obviously conservative, since they can be achieved\n13\n0 10 20 30 40 50 60\n40\n60\n80\n100\nPercentages of timely received VOPs per layer\nLa\nye\nr 1\n%\n o\nn \ntim\ne\n0 10 20 30 40 50 60\n40\n60\n80\n100\nLa\nye\nr 2\n%\n o\nn \ntim\ne\n0 10 20 30 40 50 60\n40\n60\n80\n100  \nadditional delay in frames (30 fps)\nLa\nye\nr 3\n%\n o\nn \ntim\ne\nadaptive rate\nconstant average\nadaptive rate\nconstant average\nadaptive rate\nconstant average\nFig. 14. Percentage of packets that are received on time as a function of a\nplayback delay margin K . Due to the rate adaption mechansim, roughly 10%\nof layer 3 data are not transmitted and thus never received.\nonly when the channel rate exactly correspond to the previsions. In\norder to illustrate the influence of the rate adaptation, we represent the\nnumber of packets that arrive on time, as a function of an additional\ndelay K used for decoding the streams (i.e., the actual playback\ndelays are D+K). The solid and dashed lines respectively represent\nthe behavior of the rate adaptive scheme, and of an algorithm that\ndoes not try to adapt to the actual bandwidth and simply transmits\npackets according to the pre-computed schedule. It can be seen\nthat the rate adaptive server clearly achieves better performances by\nkeeping the necessary playback delays close to the targeted ones. If\nan additional delay of only 10 frames is used at the decoder, all layers\ncan be decoded without buffer underflow. Rate adaptation therefore\npermits to efficiently control the quality of the transmission and to\nrespect the timing constraints of the streaming application. A small\nconservative margin on the playback delays is sufficient to guarantee\na smooth playback.\nFinally, we analyze the buffer occupancy at the three receivers.\nFigure 15 illustrates the buffer fullness for playback delays of D and\nD+10. In the second case, which ensures a smooth playback delay,\nwe have computed the maximum difference between the actual buffer\noccupation and the optimal buffer occupation in the ideal scenario\nwith a CBR channel rate of 32kbps. We can see that the difference\nwith the ideal scenario is always lower than 10kbytes, which is a\nnegligible penalty.\nD. Discussion\nThe experimental results show that even a simple rate adaption\nalgorithm based on partial channel knowledge can yield results that\nare close to optimal in terms of both targeted playback delays and\nbuffer occupancy, at the expense of some minor and controllable\nPSNR degradations. It is worth to be noted that our experimental\nsetup behaves like an overly nice network, as any injection of data at\na higher rate than the actual channel rate results in a pure delay at the\nreceiver. There are no losses due to buffer overflows (congestions) in\nthe network. If such losses happen, we expect that the rate adaptive\nsystem is less affected than the non-adaptive server, since it makes\neffort to avoid congestions by changing the sending rate according\nto the available bandwidth.\nFinally, the additional playback delay that is needed to compensate\nthe discrepancies between estimated rate and actual channel rate can\nbe negotiated between the server and the clients at the beginning of\nthe streaming session. They represent a trade-off between resiliency\nto channel variations and the waiting time before decoding that is\nusually kept minimal.\nVI. CONCLUSIONS\nThis paper has described the problem of scalable media scheduling\nin broadcast scenarios. In particular, we have shown the playback\ndelay can generally not be jointly minimized for all the receivers. It\ntypically represents the price to pay for applications where different\nusers simultaneously subscribe to different quality levels of the same\nstream. We have presented a reduced complexity solution for optimiz-\ning the delay in a set of receivers. When the optimal strategy consists\nin minimizing the variance of the delay penalties, we have proposed\nlow complexity algorithms that compute the optimal delay set. When\ndelays are fixed, we have shown that there is a unique scheduling\nsolution that minimizes the buffer occupancy at all the receivers\nsimultaneously. If both problems are solved sequentially, one can\nachieve jointly an optimal delay selection and a minimal buffer\noccupancy. Finally, we have proposed a rate adaptation algorithm,\nwhich deals with unpredictable channel bandwidth variations. This\nsimple scheme permits to achieve close to optimal results, even when\nthe knowledge about the channel status is limited. It provides a viable\nalternative to conservative packet scheduling in practical streaming\nscenarios.\nREFERENCES\n[1] J. Rexford and D. Towsley, \u201cSmoothing variable-bit-rate video in an\ninternetwork,\u201d IEEE/ACM Transactions on Networking, vol. 7, pp. 202\u2013\n215, April 1999.\n[2] J. Zhang and J. Hui, \u201cApplying traffic smoothing techniques for quality\nof service control in vbr video transmissions,\u201d Computer Communica-\ntions, vol. 21, pp. 375\u2013389, April 1998.\n[3] J. McManus and K. Ross, \u201cVideo-on-demand over atm: constant-\nrate transmission and transport,\u201d IEEE Journal on Selected Areas in\nCommunications, vol. 14, pp. 1087\u20131098, Aug 1996.\n[4] P. Thiran, J.-Y. Le Boudec, and F. Worm, \u201cNetwork calculus applied\nto optimal multimedia smoothing,\u201d in Proceedings of Infocom, vol. 3,\npp. 1474\u20131483, IEEE, April 2001.\n[5] J.-Y. Le Boudec and O. Verscheure, \u201cOptimal smoothing for guaranteed\nservice,\u201d IEEE/ACM Transactions on Networking, vol. 8, pp. 689\u2013696,\nDec 2000.\n[6] D. Saparilla and K. W. Ross, \u201cOptimal Streaming of Layered Video,\u201d in\nProceedings of Infocom, vol. 2, (Tel Aviv, Israel), pp. 737\u2013746, IEEE,\nMarch 2000.\n[7] P. de Cuetos and K. W. Ross, \u201cOptimal streaming of layered video: joint\nscheduling and error concealment,\u201d in Proceedings of ACM Multimedia,\n(New York, NY, USA), pp. 55\u201364, ACM Press, 2003.\n[8] Miao Z. and Ortega A., \u201cOptimal scheduling for streaming of scalable\nmedia,\u201d in Proceedings of the Thirty-Sixth Asilomar Conference on\nSignals, Systems and Computers, vol. 2, pp. 1357\u20131362, October 2000.\n[9] W. Feng, \u201cRate-constrained bandwidth smoothing for the delivery of\nstored video,\u201d in Proceedings of IS&T/SPIE Multimedia Networking and\nComputing, pp. 316\u2013327, SPIE, Feb 1997.\n[10] W. Zhao and S. K. Tripathi, \u201cBandwidth-Efficient Continuous Media\nStreaming Through Optimal Multiplexing,\u201d in Proceedings of SIGMET-\nRICS, (Atlanta, GA, USA), pp. 13\u201322, ACM, 1999.\n[11] S. McCanne, V. Jacobson, and M. Vetterli, \u201cReceiver-Driven Layered\nMulticast,\u201d in Proceedings of ACM SIGCOMM, vol. 26, (New York,\nNY), pp. 117\u2013130, ACM, August 1996.\n[12] Q. Zhang, Q. Guo, W. Zhu, and Y.-Q. Zhang, \u201cSender-Adaptive and\nReceiver-Driven Layered Multicast for Scalable Video Over the Inter-\nnet,\u201d IEEE Transactions on Circuits and Systems for Video Technology,\nvol. 15, pp. 482\u2013495, April 2005.\n[13] P. A. Chou and Z. Miao, \u201cRate-distortion optimized streaming of\npacketized media,\u201d IEEE Transactions on Multimedia, vol. 8, April 2006.\n[14] P. D. Cuetos and K. W. Ross, \u201cUnified Framework for Optimal Video\nStreaming,\u201d in Proceedings of Infocom, vol. 3, (Hong Kong), pp. 1479\u2013\n1489, IEEE, March 2004.\n14\n0 200 400 600 800 1000 1200\n0\n50\n100\n150\n200\n250\n300\n350\n400\n450\ntime in frames (30fps)\nMaximum difference from optimum:\n20.9kB \n0 200 400 600 800 1000 1200\n\u221240\n\u221220\n0\n2\n4\n6\n8\n10\ntime in frames (30fps)\n[kb\nit]\nBuffer Occupation at R 1\nMaximum difference from optimum:\n9.06kB \nPlayback delay D1\nPlayback delay D1+10\n0 200 400 600 800 1000 1200\n\u221210\n-5\n0\n5\n10\n50\n20\n25\ntime in frames (30fps)\nMaximum difference from optimum:\n18.9kB \n[kb\nit]\nBuffer Occupation at R 2\n[kb\nit]\nBuffer Occupation at R 3\nPlayback delay D2\nPlayback delay D2+10\nPlayback delay D3\nPlayback delay D3+10\nFig. 15. Receiver buffer occupancy using the rate adaptive streaming algorithm.\n[15] P. Thiran and J.-Y. L. Boudec, Network Calculus, vol. 2050 of Lecture\nNotes on Computer Science. Springer-Verlag GmbH, 2001.\n[16] W. Li, \u201cOverview of Fine Granularity Scalability in MPEG-4 Video Stan-\ndard,\u201d IEEE Transactions on Circuits and Systems for Video Technology,\nvol. 11, pp. 301\u2013317, March 2001.\n[17] \u201cMomusys code, MPEG-4 verification model version 18.0.\u201d ISO/ IEC\nJTC1/SC29/WG11 Coding of Moving Pictures and Audio, Jan 2001.\n[18] T. Stockhammer, H. Jenkac, and G. Kuhn, \u201cStreaming Video over Vari-\nable Bit-Rate Wireless Channels,\u201d IEEE Transactions on Multimedia,\nvol. 6, pp. 268\u2013277, April 2004.\n[19] \u201cNistnet network emulator.\u201d http://www-x.antd.nist.gov/nistnet/.\n", "urls": ["http://infoscience.epfl.ch/record/115074", "https://infoscience.epfl.ch/record/115074/files/CSVT_joint_delay_buffer_opt_TR.pdf"], "issn": null}